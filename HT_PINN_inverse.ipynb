{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of PINN_multi_pump_test_for_K.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "import os\r\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\r\n",
        "!pwd\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "93DG5Y_upzAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable, grad\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from utils import *\r\n",
        "\r\n",
        "import time\r\n",
        "import ast\r\n",
        "import copy"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "################ colorbar type for plot ##############\r\n",
        "cmap5 = [ 'flag', 'prism', 'ocean', 'gist_earth', 'terrain', 'gist_stern',\r\n",
        "'gnuplot', 'gnuplot2', 'CMRmap', 'cubehelix', 'brg',\r\n",
        "'gist_rainbow', 'rainbow', 'jet', 'turbo', 'nipy_spectral',\r\n",
        "'gist_ncar']\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZgRucU9lAK6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class PhysicsInformedNN(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, layers_u, layers_K, input_K=None, inv_params=None, num_pumps=25):\r\n",
        "    super(PhysicsInformedNN, self).__init__()\r\n",
        "  \r\n",
        "    self.layers = layers\r\n",
        "  \r\n",
        "    self.weights_u, self.biases_u = [], []\r\n",
        "    self.weights_K, self.biases_K = self.initialize_NN(layers_K)   \r\n",
        "    self.weights = []\r\n",
        "    self.biases = []\r\n",
        "\r\n",
        "    self.preds = None\r\n",
        "\r\n",
        "    self.loss = 0.0\r\n",
        "\r\n",
        "    self.loss_list = []   \r\n",
        "    # self.loss_dict = {'neum':[], 'diri':[],'u':[],'f':[],'K':[],'around':[],'pump':[]}\r\n",
        "    self.loss_container = []\r\n",
        "    for i in range(num_pumps): \r\n",
        "      loss_dict = {'neum':[0.0], 'diri':[0.0],'u':[0.0],'f':[0.0],'K':[0.0],'around':[0.0],'pump':[0.0]}\r\n",
        "      self.loss_container.append(loss_dict)\r\n",
        "      w, b = self.initialize_NN(layers_u)\r\n",
        "      self.weights_u.append(w)\r\n",
        "      self.biases_u.append(b)\r\n",
        "    \r\n",
        "      self.weights += w\r\n",
        "      self.biases += b\r\n",
        "    self.weights += self.weights_K\r\n",
        "    self.biases += self.biases_K\r\n",
        "\r\n",
        "  def create_dK(self, K, dx, dy):\r\n",
        "    dK_cen = (K[:,2:] - K[:,0:-2])/dx/2\r\n",
        "    dK_left = (K[:,1:2] - K[:,0:1])/dx\r\n",
        "    dK_right = (K[:,-1:] - K[:,-2:-1])/dx\r\n",
        "    dKdx = np.hstack((dK_left, dK_cen, dK_right))\r\n",
        "\r\n",
        "    dK_mid = (K[2:] - K[0:-2,])/dy/2\r\n",
        "    dK_top = (K[1:2] - K[0:1])/dy\r\n",
        "    dK_bot = (K[-1:] - K[-2:-1])/dy\r\n",
        "    dKdy = np.vstack((dK_top, dK_mid, dK_bot))\r\n",
        "    \r\n",
        "    dKdx = torch.tensor(dKdx, requires_grad=True)\r\n",
        "    dKdy = torch.tensor(dKdy, requires_grad=True)\r\n",
        "    return dKdx, dKdy\r\n",
        "\r\n",
        "  def initialize_NN(self, layers):        \r\n",
        "    weights = []\r\n",
        "    biases = []\r\n",
        "    num_layers = len(layers) \r\n",
        "    for l in range(0,num_layers-1):\r\n",
        "      W = self.xavier_init(size=[layers[l], layers[l+1]])\r\n",
        "      b = Variable(torch.zeros([1,layers[l+1]], dtype=torch.float32), requires_grad=True)\r\n",
        "      weights.append(W)\r\n",
        "      biases.append(b)        \r\n",
        "    return weights, biases\r\n",
        "      \r\n",
        "  def xavier_init(self, size):\r\n",
        "    return Variable(nn.init.xavier_normal_(torch.empty(size[0], size[1])), requires_grad=True)\r\n",
        "    \r\n",
        "  def load_NN(self, layers, params):\r\n",
        "    weights = []\r\n",
        "    biases = []\r\n",
        "    params = torch.tensor(params,dtype=torch.float32)\r\n",
        "    num_layers = len(layers)\r\n",
        "    i = 1\r\n",
        "    for l in range(0,num_layers-2):\r\n",
        "      W = torch.zeros([layers[l], layers[l+1]], dtype=torch.float32)\r\n",
        "      b = torch.zeros([1,layers[l+1]], dtype=torch.float32)\r\n",
        "      W = W + params[i:i+layers[l]]\r\n",
        "      b = b + params[i+layers[l]]\r\n",
        "      i = i + layers[l] + 1\r\n",
        "      weights.append(Variable(W, requires_grad=True))\r\n",
        "      biases.append(Variable(b, requires_grad=True))\r\n",
        "\r\n",
        "    output_layer_w = Variable(params[i][:,None], requires_grad=True)\r\n",
        "    \r\n",
        "    output_layer_b = torch.zeros((1,1), dtype=torch.float32)\r\n",
        "    output_layer_b = output_layer_b + params[i+1,0]\r\n",
        "\r\n",
        "    weights.append(output_layer_w)\r\n",
        "    biases.append(Variable(output_layer_b,requires_grad=True))\r\n",
        "\r\n",
        "    return weights, biases\r\n",
        "\r\n",
        "  def neural_net(self, x, y, weights, biases):\r\n",
        "\r\n",
        "    num_layers = len(weights) + 1\r\n",
        "    H = torch.cat((x,y),1)\r\n",
        "    for l in range(0,num_layers-2):\r\n",
        "      W = weights[l]\r\n",
        "      b = biases[l]\r\n",
        "      H = torch.tanh(torch.add(torch.matmul(H, W), b))\r\n",
        "\r\n",
        "    W = weights[-1]\r\n",
        "    b = biases[-1]\r\n",
        "    Y = torch.add(torch.matmul(H, W), b) #.requires_grad_()\r\n",
        "\r\n",
        "    return Y\r\n",
        "\r\n",
        "  def neural_net_sigmoid(self, x, y, weights, biases):\r\n",
        "\r\n",
        "    num_layers = len(weights) + 1\r\n",
        "    H = torch.cat((x,y),1)\r\n",
        "    for l in range(0,num_layers-2):\r\n",
        "      W = weights[l]\r\n",
        "      b = biases[l]\r\n",
        "      H = torch.sigmoid(torch.add(torch.matmul(H, W), b))\r\n",
        "\r\n",
        "    W = weights[-1]\r\n",
        "    b = biases[-1]\r\n",
        "    Y = torch.add(torch.matmul(H, W), b) #.requires_grad_()\r\n",
        "\r\n",
        "    return Y\r\n",
        "\r\n",
        "  def neural_net_relu(self, x, y, weights, biases):\r\n",
        "    p = torch.tensor(0.001)\r\n",
        "    num_layers = len(weights) + 1\r\n",
        "    H = torch.cat((x,y),1)\r\n",
        "\r\n",
        "    W = weights[0]\r\n",
        "    b = biases[0]\r\n",
        "    H = nn.functional.relu(torch.add(torch.matmul(H, W), b))\r\n",
        "\r\n",
        "    for l in range(1,num_layers-2):\r\n",
        "      W = weights[l]\r\n",
        "      b = biases[l]\r\n",
        "      H = torch.tanh(torch.add(torch.matmul(H, W), b))\r\n",
        "    W = weights[-1]\r\n",
        "    b = biases[-1]\r\n",
        "    # Y = nn.functional.relu(torch.add(torch.matmul(H, W), b))\r\n",
        "    # Y = nn.functional.prelu(torch.add(torch.matmul(H, W), b),p)+1\r\n",
        "    Y = torch.add(torch.matmul(H, W), b)\r\n",
        "\r\n",
        "    return Y\r\n",
        "\r\n",
        "  def net_u(self, x, y, weights, biases): # head u, including Dirichlet BCs\r\n",
        "    u = self.neural_net(x, y, weights, biases)\r\n",
        "    return u\r\n",
        "  \r\n",
        "  def net_K(self, x, y): # hydraulic conductivity K\r\n",
        "    K = self.neural_net(x, y, self.weights_K, self.biases_K)\r\n",
        "    return K\r\n",
        "  \r\n",
        "  def get_loc_idx(self, x, y): # hydraulic conductivity K\r\n",
        "    x = x.detach().numpy()\r\n",
        "    y = y.detach().numpy()\r\n",
        "\r\n",
        "    x_arr = np.linspace(-1,1,self.given_K.shape[0])\r\n",
        "    y_arr = np.linspace(-1,1,self.given_K.shape[1])\r\n",
        "\r\n",
        "    xsorted = np.argsort(x_arr)\r\n",
        "    xpos = np.searchsorted(x_arr[xsorted], x)\r\n",
        "    r = xsorted[xpos]\r\n",
        "\r\n",
        "    ysorted = np.argsort(y_arr)\r\n",
        "    ypos = np.searchsorted(y_arr[ysorted], y)\r\n",
        "    c = xsorted[ypos]\r\n",
        "    # K = given_K[r, c]\r\n",
        "\r\n",
        "    return (r, c)\r\n",
        "\r\n",
        "\r\n",
        "  def net_du(self, x, y, weights, biases): # first-order derivative match, inlcuding Neumann BCs\r\n",
        "\r\n",
        "    u = self.net_u(x, y, weights, biases)#, self.weights_u, self.biases_u)\r\n",
        "\r\n",
        "    u_x = grad(u.sum(), x, create_graph=True, retain_graph=True)[0]\r\n",
        "    u_y = grad(u.sum(), y, create_graph=True)[0]\r\n",
        "\r\n",
        "    return u_x.requires_grad_(True), u_y.requires_grad_(True)\r\n",
        "\r\n",
        "  def net_dK(self, x, y): # first-order derivative of K\r\n",
        "    K = self.net_K(x, y)#, self.weights_u, self.biases_u)\r\n",
        "\r\n",
        "    K_x = grad(K.sum(), x, create_graph=True)[0]\r\n",
        "    K_y = grad(K.sum(), y, create_graph=True)[0]\r\n",
        "\r\n",
        "    return K_x.requires_grad_(True), K_y.requires_grad_(True)\r\n",
        "\r\n",
        "\r\n",
        "  def net_f(self, x, y, weights, biases): # general PDE match, usually formulated in higher-order\r\n",
        "\r\n",
        "    u_x, u_y = self.net_du(x, y, weights, biases)\r\n",
        "    u_yy = grad(u_y.sum(), y, create_graph=True)[0]\r\n",
        "    u_xx = grad(u_x.sum(), x, create_graph=True)[0]\r\n",
        "\r\n",
        "    K = self.net_K(x, y)\r\n",
        "    K_x, K_y = self.net_dK(x, y)\r\n",
        "    # K_x = grad(K.sum(), x, create_graph=True)[0]\r\n",
        "    # K_y = grad(K.sum(), y, create_graph=True)[0]\r\n",
        "\r\n",
        "    f = K*(u_yy + u_xx) + K_x*u_x + K_y*u_y\r\n",
        "\r\n",
        "    return f.requires_grad_(True)\r\n",
        "\r\n",
        "  def forward(self, x_tensors, y_tensors, weights, biases, keys=None):\r\n",
        "\r\n",
        "    if keys is None:\r\n",
        "      keys = x_tensors.keys()\r\n",
        "    else:\r\n",
        "      preds = dict()\r\n",
        "      for i in keys:\r\n",
        "          preds[i] = None\r\n",
        "\r\n",
        "    for i in keys:\r\n",
        "\r\n",
        "      if i == 'neum':\r\n",
        "        dudx_pred, dudy_pred = self.net_du(x_tensors[i], y_tensors[i], weights, biases)\r\n",
        "        # flux_pred = self.net_f(x_tensors[i], y_tensors[i])\r\n",
        "        preds[i] = dudy_pred\r\n",
        "\r\n",
        "      elif i == 'f':\r\n",
        "        f_pred = self.net_f(x_tensors[i], y_tensors[i], weights, biases)\r\n",
        "        preds[i] = f_pred\r\n",
        "\r\n",
        "      elif i == 'u':\r\n",
        "        u_pred = self.net_u(x_tensors[i], y_tensors[i], weights, biases) \r\n",
        "        preds[i] = u_pred\r\n",
        "          \r\n",
        "      elif i == 'K':\r\n",
        "        # K_pred = nn.functional.relu(self.net_K(x_tensors[i], y_tensors[i]))+1e-4\r\n",
        "        K_pred = self.net_K(x_tensors[i], y_tensors[i])\r\n",
        "\r\n",
        "        preds[i] = K_pred\r\n",
        "          \r\n",
        "      elif i == 'diri':\r\n",
        "        diri_pred = self.net_u(x_tensors[i], y_tensors[i], weights, biases) \r\n",
        "        preds[i] = diri_pred\r\n",
        "\r\n",
        "      elif i == 'pump':\r\n",
        "        p_pred = self.net_f(x_tensors[i], y_tensors[i], weights, biases)\r\n",
        "        preds[i] = p_pred\r\n",
        "\r\n",
        "    return preds\r\n",
        "\r\n",
        "  def loss_func(self, pred_dict, true_dict, pump_id, weights=None):\r\n",
        "  \r\n",
        "    loss = torch.tensor(0.0, dtype=torch.float32)\r\n",
        "    keys = pred_dict.keys()\r\n",
        "\r\n",
        "    if weights is None:\r\n",
        "      weights = dict()\r\n",
        "      for i in keys:\r\n",
        "        weights[i] = 1.0\r\n",
        "\r\n",
        "    for i in keys:\r\n",
        "      res = pred_dict[i] - true_dict[i]\r\n",
        "      loss += weights[i]*torch.mean(res.pow(2))\r\n",
        "      r = torch.mean(res.pow(2)).item()\r\n",
        "      self.loss_container[pump_id][i].append(r*weights[i])\r\n",
        "    return loss.requires_grad_()\r\n",
        "  \r\n",
        "  def customized_backward(self, loss, params):\r\n",
        "    grads = grad(loss, params, retain_graph=True)\r\n",
        "    for vid in range(len(params)):\r\n",
        "      params[vid].grad = grads[vid]\r\n",
        "    return grads\r\n",
        "\r\n",
        "  def unzip_train_dict(self, train_dict, keys=None):\r\n",
        "    if keys is None:\r\n",
        "      keys = train_dict.keys()\r\n",
        "\r\n",
        "    x_tensors = dict()\r\n",
        "    y_tensors = dict()\r\n",
        "    true_dict = dict()\r\n",
        "\r\n",
        "    for i in keys:\r\n",
        "      x_tensors[i] = train_dict[i][0]\r\n",
        "      y_tensors[i] = train_dict[i][1]\r\n",
        "      true_dict[i] = train_dict[i][2]\r\n",
        "\r\n",
        "    return (x_tensors, y_tensors, true_dict)\r\n",
        "\r\n",
        "  def train(self, epoch, data_batch, loss_func, optimizer, pred_keys=None, loss_weights=None, pump_id_list=[0], print_interval=1000):\r\n",
        "      \r\n",
        "    if pred_keys is None:\r\n",
        "      pred_keys= data_batch[0].keys()\r\n",
        "    start_time = time.time()\r\n",
        "    for i in range(epoch):\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss = 0.0\r\n",
        "      for pump_id in pump_id_list:\r\n",
        "        train_dict = data_batch[pump_id]\r\n",
        "\r\n",
        "        (x_tensors, y_tensors, true_dict) = self.unzip_train_dict(train_dict,pred_keys)\r\n",
        "        pred_dict = self.forward(x_tensors, y_tensors, self.weights_u[pump_id], self.biases_u[pump_id], keys=pred_keys)\r\n",
        "        loss += loss_func(pred_dict, true_dict, pump_id, loss_weights)\r\n",
        "\r\n",
        "      loss.backward()\r\n",
        "      self.callback(loss.detach().numpy().squeeze())\r\n",
        "\r\n",
        "      if np.remainder(len(self.loss_list),print_interval) == 1:\r\n",
        "        elapsed = time.time() - start_time\r\n",
        "        print('Iter # %d, Loss: %.8f, Time: %.4f' % (len(self.loss_list), self.loss_list[-1], elapsed))\r\n",
        "        print_loss = dict()\r\n",
        "        for pid in pump_id_list:\r\n",
        "          print_loss = \"Pump \"+ str(pid) + \": \"\r\n",
        "          for k in ['u','f','K','neum','pump','diri']:\r\n",
        "            s = k+\":\"+str(self.loss_container[pid][k][-1])+\"; \"\r\n",
        "            print_loss += s\r\n",
        "          print(print_loss)\r\n",
        "        start_time = time.time()  \r\n",
        "      \r\n",
        "      # g = self.customized_backward(loss, self.weights+self.biases)\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "    # self.pred_dict = self.forward(x_tensors, y_tensors, keys=pred_keys)\r\n",
        "    # self.loss = loss_func(self.pred_dict, true_dict) #.requires_grad_()\r\n",
        "\r\n",
        "  def callback(self, loss):\r\n",
        "    self.loss_list.append(loss)\r\n",
        "\r\n",
        "  def coor_shift(self, X, lbs, ubs):\r\n",
        "    return 2.0*(X - lbs) / (ubs - lbs) - 1\r\n",
        "\r\n",
        "  def data_loader(self, X, u, lbs, ubs):\r\n",
        "              \r\n",
        "    X = self.coor_shift(X, lbs, ubs)\r\n",
        "\r\n",
        "    x_tensor = torch.tensor(X[:,0:1], requires_grad=True, dtype=torch.float32)\r\n",
        "    y_tensor = torch.tensor(X[:,1:2], requires_grad=True, dtype=torch.float32)\r\n",
        "\r\n",
        "    u_tensor = torch.tensor(u, dtype=torch.float32)\r\n",
        "    \r\n",
        "    return (x_tensor, y_tensor, u_tensor)\r\n",
        "\r\n",
        "  def predict(self, X_input, pid=0, target='u'):\r\n",
        "    x_tensor = torch.tensor(X_input[:,0:1], dtype=torch.float32, requires_grad=True)\r\n",
        "    y_tensor = torch.tensor(X_input[:,1:2], dtype=torch.float32, requires_grad=True)\r\n",
        "    w = self.weights_u[pid]\r\n",
        "    b = self.biases_u[pid]\r\n",
        "    pred = None\r\n",
        "    if target == 'u':\r\n",
        "      pred = self.net_u(x_tensor, y_tensor, w, b).detach().numpy().squeeze()\r\n",
        "    elif target == 'du':\r\n",
        "      dudx, dudy = self.net_du(x_tensor, y_tensor, w, b)\r\n",
        "      return dudx.detach().numpy().squeeze(), dudy.detach().numpy().squeeze()\r\n",
        "    elif target == 'f':\r\n",
        "      pred = self.net_f(x_tensor, y_tensor, w, b).detach().numpy().squeeze()\r\n",
        "\r\n",
        "    elif target == 'K':\r\n",
        "      pred = self.net_K(x_tensor, y_tensor).detach().numpy().squeeze()\r\n",
        "\r\n",
        "    return pred\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "wnsywHTMpzA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "################ hydraulic conductivty field ###################\r\n",
        "logK = np.loadtxt('./example/logK_field.txt')\r\n",
        "K = np.exp(logK)\r\n",
        "(nx,ny) = logK.shape\r\n",
        "\r\n",
        "################ K measurement locations ###################\r\n",
        "K_measure_id = np.loadtxt('./example/K_measure_id_61.txt').astype(int)\r\n",
        "\r\n",
        "################ pumping well locations ###################\r\n",
        "num_wells = 25\r\n",
        "well_id = np.arange(num_wells)\r\n",
        "pump_cell_idx = np.loadtxt('./example/pump_well_id_25.txt').astype(int)\r\n",
        "\r\n",
        "################ hydraulic heads under each pumping event ###################\r\n",
        "heads = np.empty((nx*ny, num_wells))\r\n",
        "for i in range(num_wells):\r\n",
        "  head = np.loadtxt('./example/heads/head_pump'+str(i)+'.txt')\r\n",
        "  heads[:,i]=head.T.flatten()\r\n",
        "\r\n",
        "print(heads.shape)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "lByzu7hKhZ26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############### define domain with (0,0) at center ######\r\n",
        "Lox, Loy = 1, 1\r\n",
        "dx, dy = Lox/nx, Loy/ny\r\n",
        "x = np.arange((-Lox/2+dx/2),(Lox/2),dx)\r\n",
        "y = np.arange((-Lox/2+dx/2),(Lox/2),dy)\r\n",
        "\r\n",
        "X, Y = np.meshgrid(x,y)\r\n",
        "\r\n",
        "X_star = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))\r\n",
        "\r\n",
        "#################  relax region defination ##################\r\n",
        "r = 3  # half-length of relax region\r\n",
        "pump_row_idx = np.repeat(pump_cell_idx[:,None],2*r-1,1)\r\n",
        "pump_row_idx = pump_row_idx - np.arange(-r+1,r)\r\n",
        "around_idx = [pump_row_idx]\r\n",
        "for i in range(1,r):\r\n",
        "  around_idx = [pump_row_idx-nx*i] + around_idx + [nx*i+pump_row_idx]\r\n",
        "around_idx = np.hstack(around_idx)\r\n",
        "around_idx = np.delete(around_idx,int(((2*r-1)**2-1)/2),1)\r\n",
        "\r\n",
        "#################  boundary cell locations ##################\r\n",
        "id1 = np.where(X.flatten() == min(x))\r\n",
        "id2 = np.where(X.flatten() == max(x))\r\n",
        "\r\n",
        "id3 = np.where(Y.flatten() == min(y))\r\n",
        "id4 = np.where(Y.flatten() == max(y))\r\n",
        "xbound_idx = np.unique(np.hstack((id1,id2)))\r\n",
        "ybound_idx = np.unique(np.hstack((id3,id4)))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "D98vQHiBPC3i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#################### set font size ####################\r\n",
        "axis_label_font_size = 30\r\n",
        "axis_tick_font_size = 30\r\n",
        "legend_fontszie = 25\r\n",
        "colorbar_font_size = 25\r\n",
        "title_size = 30\r\n",
        "\r\n",
        "################ show logK field ###################\r\n",
        "fig2,ax2 = plt.subplots(figsize=(7,6))\r\n",
        "\r\n",
        "im2 = ax2.pcolor(X,Y,logK, cmap='jet')\r\n",
        "ax2.set_xlabel('x')\r\n",
        "ax2.set_ylabel('y')\r\n",
        "fig2.colorbar(im2, ax=ax2, orientation='vertical')\r\n",
        "ax2.scatter(X_star[K_measure_id,0], X_star[K_measure_id,1], marker='v', zorder=1, alpha= 1, c='m', s=30)\r\n",
        "ax2.set_title(\"lnK field\",fontsize=title_size)\r\n",
        "\r\n",
        "################ show water heads under a pumping event (pe) ###################\r\n",
        "pe = 12\r\n",
        "head = heads[:,pe].reshape((nx,ny))\r\n",
        "\r\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,7))\r\n",
        "im = ax.pcolor(X,Y,head)\r\n",
        "\r\n",
        "ax.scatter(X_star[pump_cell_idx[pe],0], X_star[pump_cell_idx[pe],1], marker=\"o\", zorder=1, alpha= 1, c='r', s=40, label=\"pump\")\r\n",
        "ax.scatter(X_star[around_idx[pe],0], X_star[around_idx[pe],1], zorder=1, alpha= 1.0, c='orange', s=10, label=\"relax\")\r\n",
        "ax.scatter(X_star[ybound_idx,0], X_star[ybound_idx,1], marker='s', zorder=1, alpha= 1, c='k', s=20, label=\"neum\")\r\n",
        "ax.scatter(X_star[xbound_idx,0], X_star[xbound_idx,1], marker='s', zorder=1, alpha= 1, c='dodgerblue', s=20, label=\"diri\")\r\n",
        "ax.scatter(X_star[np.delete(pump_cell_idx,pe),0], X_star[np.delete(pump_cell_idx,pe),1], zorder=1, alpha= 1, c='purple', s=20, label=\"u\")\r\n",
        "\r\n",
        "ax.set_xlabel('x',fontsize=axis_label_font_size)\r\n",
        "ax.set_ylabel('y',fontsize=axis_label_font_size)\r\n",
        "labels = [-0.4, -0.2, 0, 0.2, 0.4]\r\n",
        "ax.set_xticks(labels)\r\n",
        "ax.set_xticks(labels)\r\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\r\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\r\n",
        "\r\n",
        "ax.legend(loc='upper left',ncol=1,prop={'size': legend_fontszie}, framealpha=0, facecolor='none',borderpad=0.01,labelspacing=0.001,handletextpad=0.5, handlelength=0.2,columnspacing=0.02)\r\n",
        "\r\n",
        "cbar = fig.colorbar(im, ax=ax,ticks=[-0.125, -0.010])\r\n",
        "cbar.ax.set_ylabel('[cm]',labelpad=-30,rotation=0,va='top',size=25)\r\n",
        "cbar.ax.set_yticklabels(['-12.5', '-1.0']) \r\n",
        "cbar.ax.tick_params(labelsize=colorbar_font_size) \r\n",
        "ax.set_title('Water head of p'+str(pe),fontsize=title_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "UkYzw5sZl5IP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############# create PINN instance #############\r\n",
        "\r\n",
        "hnu = 20 # number of hidden unit in each layer of net u\r\n",
        "hnK = 20 # number of hidden unit in each layer of net K\r\n",
        "\r\n",
        "layers = [2, hnu, hnu, hnu, hnu, hnu, hnu, 1]\r\n",
        "layers_K = [2, hnK, hnK, hnK, hnK, hnK, hnK, 1]\r\n",
        "\r\n",
        "model =PhysicsInformedNN(layers,layers_K)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p7rTe2hhmdBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############# fixed data used for all nets ##########\r\n",
        "\r\n",
        "############# K measurements ##########\r\n",
        "K_star = K.flatten()[:,None]\r\n",
        "K_train = K_star[K_measure_id]\r\n",
        "X_K_train = X_star[K_measure_id]\r\n",
        "\r\n",
        "# Domain bounds   \r\n",
        "lbs = np.array([min(x),min(y)])\r\n",
        "ubs = np.array([max(x),max(y)])\r\n",
        "    \r\n",
        "################### Dirichlet BCs (left & right bound)  ##########\r\n",
        "N_diri = 64 # No. of point for Dirichlet BCs\r\n",
        "# left (x=0) and right (x=1)\r\n",
        "xx = X_star[xbound_idx]\r\n",
        "uu = np.zeros((xx.shape[0],1))\r\n",
        "\r\n",
        "X_diri_train = xx\r\n",
        "diri_train = uu\r\n",
        "\r\n",
        "################### Neumann BCs (top & bottom bound)  #############\r\n",
        "N_neum = 64  # No. of points for Neumann BCs\r\n",
        "# bottom (y = 0) and top (y=1)\r\n",
        "yy = X_star[ybound_idx]\r\n",
        "du = np.zeros((yy.shape[0],1))\r\n",
        "\r\n",
        "X_neum_train = yy\r\n",
        "neum_train = du\r\n",
        "\r\n",
        "# transform data for network training\r\n",
        "neum_data = model.data_loader(X_neum_train, neum_train, lbs, ubs)\r\n",
        "diri_data = model.data_loader(X_diri_train, diri_train, lbs, ubs)\r\n",
        "K_data = model.data_loader(X_K_train, K_train, lbs, ubs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e-PSyntTpzBM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############# specific data in each individual pumping events ##########\r\n",
        "\r\n",
        "Qp = 20   # approximated water amount changing rate in pumping grid\r\n",
        "\r\n",
        "data_batch = []   # data batch containing training data\r\n",
        "\r\n",
        "for jj in range(num_wells):\r\n",
        "  max_head_at_cell = np.max(np.abs(heads[:,jj]))\r\n",
        "  heads_scaled = heads[:,jj][:,None]/max_head_at_cell*0.01\r\n",
        "  u_star = heads_scaled\r\n",
        "\r\n",
        "  # pump well and pump rate \r\n",
        "  X_pump_train = X_star[pump_cell_idx[jj]][None,:]\r\n",
        "  pump_train = np.array([[Qp]])\r\n",
        "\r\n",
        "  # water heads at monitor wells\r\n",
        "  X_u_train = X_star[np.delete(pump_cell_idx,jj)]\r\n",
        "  u_train = u_star[np.delete(pump_cell_idx,jj)]\r\n",
        "\r\n",
        "  # cells outside pump (relax) region set for PDE constraints\r\n",
        "  region_idx = np.hstack((pump_cell_idx[jj],around_idx[jj],xbound_idx,ybound_idx))\r\n",
        "  X_f_space = np.delete(X_star, region_idx, 0)\r\n",
        "  X_f_train = X_f_space[::1]\r\n",
        "  f_train = np.zeros((X_f_train.shape[0],1))\r\n",
        "\r\n",
        "  # transform data for network training\r\n",
        "  f_data = model.data_loader(X_f_train, f_train, lbs, ubs)\r\n",
        "  u_data = model.data_loader(X_u_train, u_train, lbs, ubs)\r\n",
        "  pump_data = model.data_loader(X_pump_train, pump_train, lbs, ubs)\r\n",
        "\r\n",
        "  # Assemble data batch of training data\r\n",
        "  train_dict = {\r\n",
        "    'neum': neum_data,\r\n",
        "    'diri': diri_data,\r\n",
        "    'u': u_data,\r\n",
        "    'f': f_data,\r\n",
        "    'K': K_data,\r\n",
        "    'pump': pump_data\r\n",
        "  }\r\n",
        "\r\n",
        "  data_batch.append(train_dict)\r\n",
        "  "
      ],
      "outputs": [],
      "metadata": {
        "id": "hlBXg2UPLYVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# select pumping events for forward models\r\n",
        "pump_id_list = [0, 4, 12, 20, 24]\r\n",
        "\r\n",
        "npump = len(pump_id_list)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "t7O8_SHwuQZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ########## load existing model ##############\r\n",
        "\r\n",
        "# NK = \"_\"+str(len(K_measure_id))\r\n",
        "\r\n",
        "# for i in pump_id_list:\r\n",
        "#   params_u = np.loadtxt(save_path+\"/npump_\"+str(npump)+\"/model_u\"+NK+\"_npump_\"+str(npump)+\"_\"+str(i)+\".txt\")\r\n",
        "#   model.weights_u[i], model.biases_u[i] = model.load_NN(layers, params_u)\r\n",
        "\r\n",
        "# params_K = np.loadtxt(save_path+\"/npump_\"+str(npump)+\"/model_K\"+NK+\"_npump_\"+str(npump)+\"_.txt\")\r\n",
        "# model.weights_K, model.biases_K= model.load_NN(layers_K, params_K)\r\n",
        "\r\n",
        "# # NK = \"\"\r\n",
        "# # for i in pump_id_list:\r\n",
        "# #   params_u = np.loadtxt(save_path+\"/model_u\"+NK+\"_\"+str(i)+\".txt\")\r\n",
        "# #   model.weights_u[i], model.biases_u[i] = model.load_NN(layers, params_u)\r\n",
        "\r\n",
        "# # params_K = np.loadtxt(save_path+\"/model_K\"+NK+\".txt\")\r\n",
        "# # model.weights_K, model.biases_K= model.load_NN(layers_K, params_K)"
      ],
      "outputs": [],
      "metadata": {
        "id": "epLDnV-FhGkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hyper-parameters setup\r\n",
        "\r\n",
        "# loss type aggregated in total loss\r\n",
        "pred_ks = ['diri', 'neum', 'u', 'pump','f','K']\r\n",
        "\r\n",
        "# weight of each loss term\r\n",
        "loss_weights = {\r\n",
        "  'f': 50.0,\r\n",
        "  'u': 10000.0,\r\n",
        "  'neum': 10000.0,\r\n",
        "  'pump': 1.0,\r\n",
        "  'K': 100.0,\r\n",
        "  'diri': 20000.0\r\n",
        "}\r\n",
        "\r\n",
        "# networks coefficients to tune\r\n",
        "biases_train = []\r\n",
        "weights_train = []\r\n",
        "\r\n",
        "for pid in pump_id_list:\r\n",
        "  weights_train += model.weights_u[pid]\r\n",
        "  biases_train += model.biases_u[pid]\r\n",
        "\r\n",
        "biases_train += model.biases_K\r\n",
        "weights_train += model.weights_K\r\n",
        "\r\n",
        "# print out loss by interval = p_intervals\r\n",
        "p_intervals = 300"
      ],
      "outputs": [],
      "metadata": {
        "id": "UZflB6IIpzBP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# training process\r\n",
        "\r\n",
        "# define optimizer\r\n",
        "optimizer = torch.optim.Adam(params=weights_train+biases_train, lr=1e-3)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "model.train(10000, data_batch, model.loss_func, optimizer, pred_ks, loss_weights, pump_id_list, p_intervals)\r\n",
        "\r\n",
        "# update learn rate\r\n",
        "optimizer.lt=1e-4\r\n",
        "model.train(10000, data_batch, model.loss_func, optimizer, pred_ks, loss_weights, pump_id_list, p_intervals)\r\n",
        "\r\n",
        "optimizer.lt=1e-5\r\n",
        "model.train(10000, data_batch, model.loss_func, optimizer, pred_ks, loss_weights, pump_id_list, p_intervals)\r\n",
        "\r\n",
        "elapsed = time.time() - start_time\r\n",
        "print('Training time: %.4f' % (elapsed))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "IvkH9N9mtjnq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# relative residuals of forward models\r\n",
        "X_pred= model.coor_shift(X_star, lbs, ubs)\r\n",
        "error_u_list = []\r\n",
        "for ti in pump_id_list:\r\n",
        "  \r\n",
        "  u_true = heads[:,ti]\r\n",
        "  u_pred = model.predict(X_pred, pid=ti, target='u')\r\n",
        "  u_err = u_pred-u_true\r\n",
        "  error_u = np.linalg.norm(u_err,2)/np.linalg.norm(u_true,2)\r\n",
        "  print('Relative residual of h of pump%d: %e' % (ti,error_u))\r\n",
        "  error_u_list.append(error_u)\r\n",
        "\r\n",
        "# print(error_u_list)\r\n",
        "print(\"Min Err: \", min(error_u_list))\r\n",
        "print(\"Max Err: \", max(error_u_list))\r\n",
        "print(\"mean Err: \", np.mean(error_u_list))\r\n",
        "print(\"std Err: \", np.std(error_u_list))"
      ],
      "outputs": [],
      "metadata": {
        "id": "dClWzqVlV6dn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "################### water heads 3D surface ##################\r\n",
        "#################### set font size ####################\r\n",
        "axis_label_font_size = 10\r\n",
        "axis_tick_font_size = 30\r\n",
        "legend_fontszie = 25\r\n",
        "colorbar_font_size = 25\r\n",
        "title_size = 30\r\n",
        "\r\n",
        "ti = pump_id_list[2]\r\n",
        "X_pred= model.coor_shift(X_star, lbs, ubs)\r\n",
        "u_true = heads[:,ti]\r\n",
        "u_pred = model.predict(X_pred, pid=ti, target='u')/0.01*np.max(np.abs(u_true))\r\n",
        "\r\n",
        "u_pred = u_pred.reshape((nx,ny))\r\n",
        "u_true = u_true.reshape((nx,ny))\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(5,3), dpi=90)\r\n",
        "ax = fig.gca(projection='3d')\r\n",
        "surf = ax.plot_surface(X,Y,u_true, rstride=1, cstride=1, cmap=cm.viridis,\r\n",
        "        linewidth=0, antialiased=False)\r\n",
        "\r\n",
        "ax.set_xlabel('x', fontsize=axis_label_font_size)\r\n",
        "ax.set_ylabel('y', fontsize=axis_label_font_size)\r\n",
        "ax.zaxis.set_rotate_label(False) \r\n",
        "ax.set_zlabel('$water\\ heads (m)$',fontsize=axis_label_font_size, labelpad=10, rotation=90)\r\n",
        "ax.view_init(30,45)\r\n",
        "ax.set_title('True Water Weads')\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(5,3), dpi=90)\r\n",
        "ax = fig.gca(projection='3d')\r\n",
        "surf = ax.plot_surface(X,Y,u_pred, rstride=1, cstride=1, cmap=cm.viridis,\r\n",
        "        linewidth=0, antialiased=False)\r\n",
        "\r\n",
        "ax.set_xlabel('x', fontsize=axis_label_font_size)\r\n",
        "ax.set_ylabel('y', fontsize=axis_label_font_size)\r\n",
        "ax.zaxis.set_rotate_label(False) \r\n",
        "ax.set_zlabel('$water\\ heads (m)$',fontsize=axis_label_font_size, labelpad=10, rotation=90)\r\n",
        "ax.view_init(30,45)\r\n",
        "ax.set_title('Predicted Water Heads')"
      ],
      "outputs": [],
      "metadata": {
        "id": "tKiTO1kOpzBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# relative residuals of inverse model\r\n",
        "K_pred = model.predict(X_pred, pid=ti, target='K')\r\n",
        "K_true = K.flatten()\r\n",
        "\r\n",
        "K_err = K_true - K_pred\r\n",
        "error_K = np.linalg.norm(K_err,2)/np.linalg.norm(K_true,2)\r\n",
        "print('Relative residual of K: %e' % (error_K))\r\n",
        "\r\n",
        "################### hydraulic conductivity colormap 2D ##################\r\n",
        "K_pred = K_pred.reshape((nx,ny))\r\n",
        "minlK, maxlK = np.min(logK), np.max(logK)\r\n",
        "fig,ax = plt.subplots(figsize=(7,6))\r\n",
        "im = ax.pcolor(X,Y,logK,cmap=cmap5[13])\r\n",
        "im.set_clim(minlK, maxlK )\r\n",
        "fig.colorbar(im, ax=ax)\r\n",
        "plt.xlabel('x')\r\n",
        "plt.ylabel('y')\r\n",
        "ax.scatter(X_star[K_measure_id,0], X_star[K_measure_id,1], zorder=1, alpha= 0.8, c='r', s=15)\r\n",
        "ax.set_title('True logK Field')\r\n",
        "logK_pred = np.nan_to_num(np.log(K_pred),nan=minlK)\r\n",
        "fig,ax = plt.subplots(figsize=(7,6))\r\n",
        "im = ax.pcolor(X,Y, logK_pred,cmap=cmap5[13])\r\n",
        "im.set_clim(minlK, maxlK )\r\n",
        "\r\n",
        "fig.colorbar(im, ax=ax)\r\n",
        "plt.xlabel('x')\r\n",
        "plt.ylabel('y')\r\n",
        "ax.scatter(X_star[K_measure_id,0], X_star[K_measure_id,1], zorder=1, alpha= 0.8, c='r', s=15)\r\n",
        "ax.set_title('Predicted logK Field')\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "MiqyVLCxpzBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# accuracy of inverse model\r\n",
        "\r\n",
        "thres = 0.1   # threshold 10%\r\n",
        "K_len = maxlK-minlK\r\n",
        "\r\n",
        "relative_abs_err = abs(logK-logK_pred)/K_len\r\n",
        "accuracy = sum(sum(acc<thres))/(nx*ny)\r\n",
        "print('Accuracy of K: %e' % (accuracy))\r\n",
        "\r\n",
        "fig,ax = plt.subplots(figsize=(7,6))\r\n",
        "plt.pcolor(X,Y,relative_abs_err,cmap=plt.cm.BuPu_r)\r\n",
        "plt.colorbar()\r\n",
        "plt.xlabel('x')\r\n",
        "plt.ylabel('y')\r\n",
        "plt.title('Relative Absolute Error of logK')"
      ],
      "outputs": [],
      "metadata": {
        "id": "zfo4LlLzEmyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ############## save well-trained model: u and K ############\r\n",
        "#   try:\r\n",
        "#     os.mkdir(\"./model_coeff\")\r\n",
        "#   except:\r\n",
        "#     FileExistsError\r\n",
        "# m = model\r\n",
        "# for i in pump_id_list:\r\n",
        "#   weights = torch.ones(1,hnu)*i\r\n",
        "\r\n",
        "#   for j in range(len(layers)-2):\r\n",
        "#     w = m.weights_u[i][j]\r\n",
        "#     b = m.biases_u[i][j]\r\n",
        "#     weights = torch.vstack((weights,w,b))\r\n",
        "\r\n",
        "#   weights = torch.vstack((weights,m.weights_u[i][j+1].T,torch.ones(1,hnu)*m.biases_u[i][j+1]))\r\n",
        "#   weights=weights.detach().numpy()\r\n",
        "\r\n",
        "\r\n",
        "#   path_name = \"./model_coeff/model_u\"+\"_\"+str(i)+\".txt\"\r\n",
        "#   np.savetxt(path_name,weights)\r\n",
        "\r\n",
        "# weights = torch.ones(1,hnK)*i\r\n",
        "\r\n",
        "# for j in range(len(layers)-2):\r\n",
        "#   w = m.weights_K[j]\r\n",
        "#   b = m.biases_K[j]\r\n",
        "#   weights = torch.vstack((weights,w,b))\r\n",
        "\r\n",
        "# weights = torch.vstack((weights,m.weights_K[j+1].T,torch.ones(1,hnK)*m.biases_K[j+1]))\r\n",
        "# weights=weights.detach().numpy()\r\n",
        "\r\n",
        "# path_name = \"./model_coeff/model_K.txt\"\r\n",
        "# np.savetxt(path_name,weights)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kYdlmsjf1REY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ############## save hyper-parameters for reproduce ##################\r\n",
        "# hyper_param = copy.copy(loss_weights)\r\n",
        "# hyper_param['Qp'] = Qp\r\n",
        "# hyper_param['r'] = r\r\n",
        "# hyper_param['hnK'] = hnK\r\n",
        "# hyper_param['hnu'] = hnu\r\n",
        "# hyper_param['lenK'] = len(layers_K)\r\n",
        "# hyper_param['lenu'] = len(layers)\r\n",
        "# hyper_param['act_K'] = 'tanh'\r\n",
        "# hyper_param['act_u'] = 'tanh'\r\n",
        "# hyper_param['out_K'] = 'linear'\r\n",
        "# hyper_param['out_u'] = 'linear'\r\n",
        "\r\n",
        "# f = open(\"./model_coeff/hyper_parameters.txt\",\"w\")\r\n",
        "# f.write(str(hyper_param))\r\n",
        "# f.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "FBLmo_QDvngy"
      }
    }
  ]
}